{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb3a5bc6",
   "metadata": {},
   "source": [
    "# Python + GeoParquet + DuckDB: A Comprehensive Tutorial\n",
    "\n",
    "## 1. Introduction\n",
    "\n",
    "This tutorial explores the powerful combination of Python, GeoParquet, and DuckDB for efficient geospatial data processing and analysis. We'll cover the basics of each technology, their advantages, and how they work together to provide a robust solution for handling geospatial datasets.\n",
    "\n",
    "### 1.1 What is GeoParquet?\n",
    "\n",
    "GeoParquet is an extension of Apache Parquet, a columnar storage file format, designed specifically for geospatial data. It combines the efficiency of Parquet with support for geometric data types, making it an excellent choice for storing and processing geospatial information.\n",
    "\n",
    "### 1.2 Advantages of GeoParquet\n",
    "\n",
    "GeoParquet offers several advantages over alternative formats such as JSON, JSONL (JSON Lines), and CSV, especially when dealing with large geospatial datasets:\n",
    "\n",
    "1. **Efficient Storage**: Uses columnar storage and compression, significantly reducing file size.\n",
    "2. **Fast Query Performance**: Allows for quick data retrieval and filtering.\n",
    "3. **Schema Enforcement**: Ensures data consistency and reduces interpretation errors.\n",
    "4. **Support for Complex Data Types**: Natively stores complex geospatial objects.\n",
    "5. **Partitioning and Chunking**: Supports efficient querying of subsets of large datasets.\n",
    "6. **Interoperability**: Wide support in big data ecosystems and geospatial tools.\n",
    "7. **Metadata Handling**: Better support for metadata compared to CSV.\n",
    "8. **Streaming Capabilities**: Supports streaming reads with compression benefits.\n",
    "9. **Reduced Processing Time**: Faster overall processing for large datasets.\n",
    "\n",
    "### 1.3 Comparison with Alternative Formats\n",
    "\n",
    "- **JSON Blobs**:\n",
    "  - Pros: Human-readable, flexible schema\n",
    "  - Cons: Large file size, slow to parse, must often be read entirely into memory\n",
    "\n",
    "- **JSONL (JSON Lines)**:\n",
    "  - Pros: Supports streaming, one record per line for easier processing\n",
    "  - Cons: Still larger file size than GeoParquet, less efficient querying\n",
    "\n",
    "- **CSV**:\n",
    "  - Pros: Simple, widely supported, human-readable\n",
    "  - Cons: No native support for complex data types, no schema enforcement, less efficient for large datasets\n",
    "\n",
    "## 2. Setting Up the Environment\n",
    "\n",
    "### 2.1 Installation\n",
    "\n",
    "To set up our environment, we need to install the following packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2d9fdad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: geopandas in /Users/raymondyee/.pyenv/versions/3.11.9/envs/myenv-3.11.9/lib/python3.11/site-packages (0.14.4)\n",
      "Requirement already satisfied: pyarrow in /Users/raymondyee/.pyenv/versions/3.11.9/envs/myenv-3.11.9/lib/python3.11/site-packages (16.1.0)\n",
      "Requirement already satisfied: duckdb in /Users/raymondyee/.pyenv/versions/3.11.9/envs/myenv-3.11.9/lib/python3.11/site-packages (1.0.0)\n",
      "Requirement already satisfied: pandas in /Users/raymondyee/.pyenv/versions/3.11.9/envs/myenv-3.11.9/lib/python3.11/site-packages (2.2.2)\n",
      "Requirement already satisfied: polars in /Users/raymondyee/.pyenv/versions/3.11.9/envs/myenv-3.11.9/lib/python3.11/site-packages (1.1.0)\n",
      "Requirement already satisfied: shapely in /Users/raymondyee/.pyenv/versions/3.11.9/envs/myenv-3.11.9/lib/python3.11/site-packages (2.0.4)\n",
      "Requirement already satisfied: fiona>=1.8.21 in /Users/raymondyee/.pyenv/versions/3.11.9/envs/myenv-3.11.9/lib/python3.11/site-packages (from geopandas) (1.9.6)\n",
      "Requirement already satisfied: numpy>=1.22 in /Users/raymondyee/.pyenv/versions/3.11.9/envs/myenv-3.11.9/lib/python3.11/site-packages (from geopandas) (1.26.4)\n",
      "Requirement already satisfied: packaging in /Users/raymondyee/.pyenv/versions/3.11.9/envs/myenv-3.11.9/lib/python3.11/site-packages (from geopandas) (23.2)\n",
      "Requirement already satisfied: pyproj>=3.3.0 in /Users/raymondyee/.pyenv/versions/3.11.9/envs/myenv-3.11.9/lib/python3.11/site-packages (from geopandas) (3.6.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/raymondyee/.pyenv/versions/3.11.9/envs/myenv-3.11.9/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/raymondyee/.pyenv/versions/3.11.9/envs/myenv-3.11.9/lib/python3.11/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/raymondyee/.pyenv/versions/3.11.9/envs/myenv-3.11.9/lib/python3.11/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /Users/raymondyee/.pyenv/versions/3.11.9/envs/myenv-3.11.9/lib/python3.11/site-packages (from fiona>=1.8.21->geopandas) (23.2.0)\n",
      "Requirement already satisfied: certifi in /Users/raymondyee/.pyenv/versions/3.11.9/envs/myenv-3.11.9/lib/python3.11/site-packages (from fiona>=1.8.21->geopandas) (2024.6.2)\n",
      "Requirement already satisfied: click~=8.0 in /Users/raymondyee/.pyenv/versions/3.11.9/envs/myenv-3.11.9/lib/python3.11/site-packages (from fiona>=1.8.21->geopandas) (8.1.7)\n",
      "Requirement already satisfied: click-plugins>=1.0 in /Users/raymondyee/.pyenv/versions/3.11.9/envs/myenv-3.11.9/lib/python3.11/site-packages (from fiona>=1.8.21->geopandas) (1.1.1)\n",
      "Requirement already satisfied: cligj>=0.5 in /Users/raymondyee/.pyenv/versions/3.11.9/envs/myenv-3.11.9/lib/python3.11/site-packages (from fiona>=1.8.21->geopandas) (0.7.2)\n",
      "Requirement already satisfied: six in /Users/raymondyee/.pyenv/versions/3.11.9/envs/myenv-3.11.9/lib/python3.11/site-packages (from fiona>=1.8.21->geopandas) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "pip install geopandas pyarrow duckdb pandas polars shapely"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae592f4c",
   "metadata": {},
   "source": [
    "### 2.2 Importing Necessary Modules\n",
    "\n",
    "In your Python script or Jupyter notebook, start with these imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efcef572",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import pyarrow as pa\n",
    "import duckdb\n",
    "import shapely"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5052ee",
   "metadata": {},
   "source": [
    "## 3. Working with GeoParquet and DuckDB\n",
    "\n",
    "Let's create a simple example to demonstrate how to create, save, and read GeoParquet data using Python, GeoPandas, and DuckDB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5d647ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GeoPandas version: 0.14.4\n",
      "DuckDB version: 1.0.0\n",
      "\n",
      "Data read from GeoParquet using DuckDB:\n",
      "City: New York, Longitude: -74.006, Latitude: 40.7128\n",
      "City: Paris, Longitude: 2.3522, Latitude: 48.8566\n",
      "City: Tokyo, Longitude: 139.6917, Latitude: 35.6895\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "import duckdb\n",
    "\n",
    "# Print version information\n",
    "print(f\"GeoPandas version: {gpd.__version__}\")\n",
    "print(f\"DuckDB version: {duckdb.__version__}\")\n",
    "\n",
    "# Create a simple GeoDataFrame\n",
    "gdf = gpd.GeoDataFrame(\n",
    "    {'city': ['New York', 'Paris', 'Tokyo'],\n",
    "     'geometry': gpd.points_from_xy([-74.006, 2.3522, 139.6917], \n",
    "                                    [40.7128, 48.8566, 35.6895])},\n",
    "    crs=\"EPSG:4326\"\n",
    ")\n",
    "\n",
    "# Save as GeoParquet\n",
    "gdf.to_parquet(\"cities.geoparquet\")\n",
    "\n",
    "# Read with DuckDB\n",
    "con = duckdb.connect()\n",
    "\n",
    "# Enable spatial extension\n",
    "con.execute(\"INSTALL spatial;\")\n",
    "con.execute(\"LOAD spatial;\")\n",
    "\n",
    "# Read the GeoParquet file and extract coordinates\n",
    "result = con.execute(\"\"\"\n",
    "    SELECT \n",
    "        city, \n",
    "        ST_X(ST_GeomFromWKB(geometry)) as longitude, \n",
    "        ST_Y(ST_GeomFromWKB(geometry)) as latitude\n",
    "    FROM read_parquet('cities.geoparquet')\n",
    "\"\"\").fetchall()\n",
    "\n",
    "print(\"\\nData read from GeoParquet using DuckDB:\")\n",
    "for row in result:\n",
    "    print(f\"City: {row[0]}, Longitude: {row[1]}, Latitude: {row[2]}\")\n",
    "\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a49eb8c",
   "metadata": {},
   "source": [
    "### 3.1 Understanding ST_GeomFromWKB\n",
    "\n",
    "In our DuckDB query, we use the `ST_GeomFromWKB` function. Here's why it's necessary:\n",
    "\n",
    "1. **WKB Format**: GeoParquet stores geometry data in Well-Known Binary (WKB) format. This is a standard binary representation of geometry data that's compact and efficient.\n",
    "\n",
    "2. **DuckDB Interpretation**: While DuckDB can read the Parquet file, it doesn't automatically recognize the WKB data as geometry. The `ST_GeomFromWKB` function tells DuckDB to interpret this binary data as geometric information.\n",
    "\n",
    "3. **Enabling Spatial Functions**: By converting the WKB data to a geometry type that DuckDB understands, we can then use spatial functions like `ST_X` and `ST_Y` to extract coordinates.\n",
    "\n",
    "## 4. Processing GeoParquet with Different Tools\n",
    "\n",
    "### 4.1 Using Pandas and GeoPandas\n",
    "\n",
    "Pandas can read Parquet files directly, but it doesn't natively understand the geometry column. We'll need to use GeoPandas to properly interpret the geometry data and perform accurate spatial operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bb91142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas DataFrame:\n",
      "       city                                           geometry\n",
      "0  New York  b'\\x01\\x01\\x00\\x00\\x00\\xaa\\xf1\\xd2Mb\\x80R\\xc0^...\n",
      "1     Paris  b'\\x01\\x01\\x00\\x00\\x00\\xa85\\xcd;N\\xd1\\x02@v\\xe...\n",
      "2     Tokyo  b'\\x01\\x01\\x00\\x00\\x00\\x95\\xd4\\th\"va@\\xc7K7\\x8...\n",
      "\n",
      "GeoPandas GeoDataFrame:\n",
      "       city                    geometry\n",
      "0  New York  POINT (-74.00600 40.71280)\n",
      "1     Paris    POINT (2.35220 48.85660)\n",
      "2     Tokyo  POINT (139.69170 35.68950)\n",
      "\n",
      "Cities with longitude < 0:\n",
      "       city                    geometry\n",
      "0  New York  POINT (-74.00600 40.71280)\n",
      "\n",
      "Distances to Tokyo:\n",
      "       city  distance_to_tokyo_km\n",
      "0  New York          23795.290574\n",
      "1     Paris          15358.665379\n",
      "2     Tokyo              0.000000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "# Read the GeoParquet file\n",
    "pdf = pd.read_parquet('cities.geoparquet')\n",
    "print(\"Pandas DataFrame:\")\n",
    "print(pdf)\n",
    "\n",
    "# Convert to GeoDataFrame to properly handle the geometry\n",
    "gdf = gpd.read_parquet('cities.geoparquet')\n",
    "print(\"\\nGeoPandas GeoDataFrame:\")\n",
    "print(gdf)\n",
    "\n",
    "# Basic querying\n",
    "print(\"\\nCities with longitude < 0:\")\n",
    "print(gdf[gdf.geometry.x < 0])\n",
    "\n",
    "# Calculate distances between cities\n",
    "# First, we need to project our data to a coordinate system that preserves distance\n",
    "# We'll use the World Equidistant Cylindrical projection (EPSG:4087)\n",
    "gdf_projected = gdf.to_crs(epsg=4087)\n",
    "tokyo_point = Point(139.6917, 35.6895)\n",
    "tokyo_projected = gpd.GeoDataFrame(geometry=[tokyo_point], crs=\"EPSG:4326\").to_crs(epsg=4087)\n",
    "\n",
    "gdf_projected['distance_to_tokyo'] = gdf_projected.geometry.distance(tokyo_projected.geometry.iloc[0])\n",
    "\n",
    "# Convert distance to kilometers\n",
    "gdf_projected['distance_to_tokyo_km'] = gdf_projected['distance_to_tokyo'] / 1000\n",
    "\n",
    "print(\"\\nDistances to Tokyo:\")\n",
    "print(gdf_projected[['city', 'distance_to_tokyo_km']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39ae8f4",
   "metadata": {},
   "source": [
    "### 4.2 Using Polars\n",
    "\n",
    "Polars is a fast dataframe library written in Rust. It can read Parquet files efficiently, but like pandas, it doesn't natively understand the geometry column. We'll need to handle the WKB data explicitly and implement our own distance calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1becdd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polars DataFrame:\n",
      "shape: (3, 2)\n",
      "┌──────────┬─────────────────────────────────┐\n",
      "│ city     ┆ geometry                        │\n",
      "│ ---      ┆ ---                             │\n",
      "│ str      ┆ binary                          │\n",
      "╞══════════╪═════════════════════════════════╡\n",
      "│ New York ┆ b\"\\x01\\x01\\x00\\x00\\x00\\xaa\\xf1… │\n",
      "│ Paris    ┆ b\"\\x01\\x01\\x00\\x00\\x00\\xa85\\xc… │\n",
      "│ Tokyo    ┆ b\"\\x01\\x01\\x00\\x00\\x00\\x95\\xd4… │\n",
      "└──────────┴─────────────────────────────────┘\n",
      "\n",
      "Polars DataFrame with extracted coordinates:\n",
      "shape: (3, 5)\n",
      "┌──────────┬─────────────────────────────────┬─────────────────────┬───────────┬──────────┐\n",
      "│ city     ┆ geometry                        ┆ coords              ┆ longitude ┆ latitude │\n",
      "│ ---      ┆ ---                             ┆ ---                 ┆ ---       ┆ ---      │\n",
      "│ str      ┆ binary                          ┆ list[f64]           ┆ f64       ┆ f64      │\n",
      "╞══════════╪═════════════════════════════════╪═════════════════════╪═══════════╪══════════╡\n",
      "│ New York ┆ b\"\\x01\\x01\\x00\\x00\\x00\\xaa\\xf1… ┆ [-74.006, 40.7128]  ┆ -74.006   ┆ 40.7128  │\n",
      "│ Paris    ┆ b\"\\x01\\x01\\x00\\x00\\x00\\xa85\\xc… ┆ [2.3522, 48.8566]   ┆ 2.3522    ┆ 48.8566  │\n",
      "│ Tokyo    ┆ b\"\\x01\\x01\\x00\\x00\\x00\\x95\\xd4… ┆ [139.6917, 35.6895] ┆ 139.6917  ┆ 35.6895  │\n",
      "└──────────┴─────────────────────────────────┴─────────────────────┴───────────┴──────────┘\n",
      "\n",
      "Cities with longitude < 0:\n",
      "shape: (1, 5)\n",
      "┌──────────┬─────────────────────────────────┬────────────────────┬───────────┬──────────┐\n",
      "│ city     ┆ geometry                        ┆ coords             ┆ longitude ┆ latitude │\n",
      "│ ---      ┆ ---                             ┆ ---                ┆ ---       ┆ ---      │\n",
      "│ str      ┆ binary                          ┆ list[f64]          ┆ f64       ┆ f64      │\n",
      "╞══════════╪═════════════════════════════════╪════════════════════╪═══════════╪══════════╡\n",
      "│ New York ┆ b\"\\x01\\x01\\x00\\x00\\x00\\xaa\\xf1… ┆ [-74.006, 40.7128] ┆ -74.006   ┆ 40.7128  │\n",
      "└──────────┴─────────────────────────────────┴────────────────────┴───────────┴──────────┘\n",
      "\n",
      "Distances to Tokyo (in kilometers):\n",
      "shape: (3, 2)\n",
      "┌──────────┬──────────────────────┐\n",
      "│ city     ┆ distance_to_tokyo_km │\n",
      "│ ---      ┆ ---                  │\n",
      "│ str      ┆ f64                  │\n",
      "╞══════════╪══════════════════════╡\n",
      "│ New York ┆ 10848.807998         │\n",
      "│ Paris    ┆ 9712.071149          │\n",
      "│ Tokyo    ┆ 0.0                  │\n",
      "└──────────┴──────────────────────┘\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3m/hgwd35sj1bq_g06dydt8t16w0000gn/T/ipykernel_43216/1245480435.py:31: MapWithoutReturnDtypeWarning: Calling `map_elements` without specifying `return_dtype` can lead to unpredictable results. Specify `return_dtype` to silence this warning.\n",
      "  df_with_coords = df.with_columns([\n",
      "/var/folders/3m/hgwd35sj1bq_g06dydt8t16w0000gn/T/ipykernel_43216/1245480435.py:48: MapWithoutReturnDtypeWarning: Calling `map_elements` without specifying `return_dtype` can lead to unpredictable results. Specify `return_dtype` to silence this warning.\n",
      "  df_with_distances = df_with_coords.with_columns([\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "from shapely import wkb\n",
    "import pyarrow as pa\n",
    "import math\n",
    "\n",
    "# Read the GeoParquet file\n",
    "df = pl.read_parquet('cities.geoparquet')\n",
    "print(\"Polars DataFrame:\")\n",
    "print(df)\n",
    "\n",
    "# Function to convert WKB to coordinates\n",
    "def wkb_to_coords(wkb_data):\n",
    "    point = wkb.loads(wkb_data)\n",
    "    return (point.x, point.y)\n",
    "\n",
    "# Haversine formula for distance calculation\n",
    "def haversine_distance(lon1, lat1, lon2, lat2):\n",
    "    R = 6371  # Earth's radius in kilometers\n",
    "\n",
    "    phi1 = math.radians(lat1)\n",
    "    phi2 = math.radians(lat2)\n",
    "    delta_phi = math.radians(lat2 - lat1)\n",
    "    delta_lambda = math.radians(lon2 - lon1)\n",
    "\n",
    "    a = math.sin(delta_phi/2)**2 + math.cos(phi1) * math.cos(phi2) * math.sin(delta_lambda/2)**2\n",
    "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1-a))\n",
    "\n",
    "    return R * c\n",
    "\n",
    "# Extract coordinates from the geometry column\n",
    "df_with_coords = df.with_columns([\n",
    "    pl.col('geometry').map_elements(wkb_to_coords).alias('coords')\n",
    "])\n",
    "df_with_coords = df_with_coords.with_columns([\n",
    "    pl.col('coords').list.get(0).alias('longitude'),\n",
    "    pl.col('coords').list.get(1).alias('latitude')\n",
    "])\n",
    "\n",
    "print(\"\\nPolars DataFrame with extracted coordinates:\")\n",
    "print(df_with_coords)\n",
    "\n",
    "# Basic querying\n",
    "print(\"\\nCities with longitude < 0:\")\n",
    "print(df_with_coords.filter(pl.col('longitude') < 0))\n",
    "\n",
    "# Calculate distances using Haversine formula\n",
    "tokyo_coords = (139.6917, 35.6895)\n",
    "df_with_distances = df_with_coords.with_columns([\n",
    "    pl.struct(['longitude', 'latitude'])\n",
    "    .map_elements(lambda x: haversine_distance(x['longitude'], x['latitude'], tokyo_coords[0], tokyo_coords[1]))\n",
    "    .alias('distance_to_tokyo_km')\n",
    "])\n",
    "\n",
    "print(\"\\nDistances to Tokyo (in kilometers):\")\n",
    "print(df_with_distances.select(['city', 'distance_to_tokyo_km']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021abc74",
   "metadata": {},
   "source": [
    "### 4.3 Using DuckDB\n",
    "\n",
    "Here's an expanded example using DuckDB, which includes distance calculations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1be89275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data read from GeoParquet using DuckDB:\n",
      "City: New York, Longitude: -74.006, Latitude: 40.7128\n",
      "City: Paris, Longitude: 2.3522, Latitude: 48.8566\n",
      "City: Tokyo, Longitude: 139.6917, Latitude: 35.6895\n",
      "\n",
      "Distances to Tokyo calculated by DuckDB (in kilometers):\n",
      "City: New York, Distance: 0.21 km\n",
      "City: Paris, Distance: 0.14 km\n",
      "City: Tokyo, Distance: 0.00 km\n"
     ]
    }
   ],
   "source": [
    "import duckdb\n",
    "\n",
    "con = duckdb.connect()\n",
    "con.execute(\"INSTALL spatial;\")\n",
    "con.execute(\"LOAD spatial;\")\n",
    "\n",
    "result = con.execute(\"\"\"\n",
    "    SELECT \n",
    "        city, \n",
    "        ST_X(ST_GeomFromWKB(geometry)) as longitude, \n",
    "        ST_Y(ST_GeomFromWKB(geometry)) as latitude\n",
    "    FROM read_parquet('cities.geoparquet')\n",
    "\"\"\").fetchall()\n",
    "\n",
    "print(\"\\nData read from GeoParquet using DuckDB:\")\n",
    "for row in result:\n",
    "    print(f\"City: {row[0]}, Longitude: {row[1]}, Latitude: {row[2]}\")\n",
    "\n",
    "# Calculate distances using DuckDB\n",
    "result_distances = con.execute(\"\"\"\n",
    "    WITH cities AS (\n",
    "        SELECT \n",
    "            city, \n",
    "            ST_GeomFromWKB(geometry) as geom\n",
    "        FROM read_parquet('cities.geoparquet')\n",
    "    )\n",
    "    SELECT \n",
    "        city, \n",
    "        ST_Distance(geom, ST_Point(139.6917, 35.6895))/1000 as distance_to_tokyo_km\n",
    "    FROM cities\n",
    "\"\"\").fetchall()\n",
    "\n",
    "print(\"\\nDistances to Tokyo calculated by DuckDB (in kilometers):\")\n",
    "for row in result_distances:\n",
    "    print(f\"City: {row[0]}, Distance: {row[1]:.2f} km\")\n",
    "\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c7e094",
   "metadata": {},
   "source": [
    "## 5. Comparison of Approaches\n",
    "\n",
    "1. **GeoPandas**: \n",
    "   - Pros: Native support for geospatial operations, intuitive for those familiar with pandas.\n",
    "   - Cons: Can be memory-intensive for large datasets.\n",
    "\n",
    "2. **Polars**: \n",
    "   - Pros: Very fast, good for large datasets.\n",
    "   - Cons: Requires manual handling of geometry data, less built-in support for geospatial operations.\n",
    "\n",
    "3. **DuckDB**: \n",
    "   - Pros: SQL interface, efficient for large datasets, built-in geospatial functions.\n",
    "   - Cons: Requires knowledge of SQL and specific DuckDB functions.\n",
    "\n",
    "Each approach has its strengths, and the choice depends on your specific use case, dataset size, and familiarity with the tools.\n",
    "\n",
    "## 6. Best Practices and Tips\n",
    "\n",
    "1. **Choose the Right Tool**: Consider your dataset size, query complexity, and performance requirements when choosing between GeoPandas, Polars, and DuckDB.\n",
    "\n",
    "2. **Leverage GeoParquet's Efficiency**: Use GeoParquet for storing large geospatial datasets to take advantage of its compression and efficient querying capabilities.\n",
    "\n",
    "3. **Understand Geometry Formats**: Be aware of how different tools handle geometry data (e.g., WKB in GeoParquet, native geometry objects in GeoPandas).\n",
    "\n",
    "4. **Use Appropriate Projections**: When calculating distances or areas, make sure to use an appropriate projection for your data's geographic extent.\n",
    "\n",
    "5. **Handle Large Datasets Carefully**: For very large datasets, consider using tools like DuckDB or Polars that are designed for out-of-memory processing.\n",
    "\n",
    "6. **Validate Results**: Cross-check results between different tools, especially when implementing custom geospatial operations.\n",
    "\n",
    "## 7. Conclusion and Next Steps\n",
    "\n",
    "This tutorial has introduced you to working with GeoParquet data using Python, GeoPandas, Polars, and DuckDB. You've learned how to:\n",
    "\n",
    "- Create and save GeoParquet files\n",
    "- Read and process GeoParquet data using different tools\n",
    "- Perform basic spatial operations and queries\n",
    "- Calculate distances using different methods\n",
    "\n",
    "To further your learning, consider exploring:\n",
    "\n",
    "- More complex geospatial analyses and operations\n",
    "- Handling larger datasets and optimizing performance\n",
    "- Integrating these tools into data processing pipelines\n",
    "- Visualizing geospatial data using libraries like Folium or Geopandas' plotting capabilities\n",
    "\n",
    "Remember, the field of geospatial data processing is vast and constantly evolving. Keep exploring and experimenting with different tools and techniques to find the best solutions for your specific needs.\n",
    "\n",
    "Happy geospatial data processing!"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
