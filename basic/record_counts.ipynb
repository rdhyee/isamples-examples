{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Purpose of this notebook\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt: using the subprocess module, run pip install -r on the file at https://raw.githubusercontent.com/rdhyee/isamples-examples/exploratory/requirements.in\n",
    "\n",
    "import subprocess\n",
    "\n",
    "def in_colab():\n",
    "    try:\n",
    "        from IPython.core import getipython\n",
    "        return 'google.colab' in str(getipython.get_ipython())\n",
    "    except ImportError:\n",
    "        # Not running in an IPython environment\n",
    "        return False\n",
    "\n",
    "\n",
    "if in_colab():\n",
    "  subprocess.run(['pip', 'install', '-r', 'https://raw.githubusercontent.com/rdhyee/isamples-examples/exploratory/requirements.in'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pybash macro\n",
    "# https://stackoverflow.com/a/67029719/7782\n",
    "from IPython import get_ipython\n",
    "from IPython.core.magic import register_cell_magic\n",
    "\n",
    "ipython = get_ipython()\n",
    "\n",
    "@register_cell_magic\n",
    "def pybash(line, cell):\n",
    "    ipython.run_cell_magic('bash', '', cell.format(**globals()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-28T13:01:34.491834Z",
     "start_time": "2023-10-28T13:01:34.342886Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "import httpx\n",
    "import xarray\n",
    "import pysolr\n",
    "import multidict\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "from urllib.parse import quote\n",
    "\n",
    "import pandas as pd\n",
    "from pandas import DataFrame, Series\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import Counter\n",
    "from isbclient import IsbClient, MAJOR_FIELDS, FL_DEFAULT, FACET_FIELDS_DEFAULT, FACET_RANGE_FIELDS_DEFAULT, ISAMPLES_SOURCES\n",
    "\n",
    "# creating a subclass of IsbClient because we're still working out the best ways to interact with the API\n",
    "from isbclient import IsbClient2\n",
    "\n",
    "from isbclient import format_date_for_solr, create_date_range_query, filter_null_values\n",
    "from isbclient import monkey_patch_select, SWITCH_TO_POST\n",
    "\n",
    "\n",
    "from itertools import islice\n",
    "\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "# monkeypatch pysolr?\n",
    "monkey_patch_select(active=True)\n",
    "SWITCH_TO_POST = 10000\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The overall iSamples API\n",
    "\n",
    "* https://central.isample.xyz/isamples_central/docs is the swagger UI\n",
    "* https://central.isample.xyz/isamples_central/openapi.json is the OpenAPI spec file for the iSamples API.\n",
    "\n",
    "There are Python libraries for enabling devs to interact with an API specified by an OpenAPI spec, but my current thought is that they don't make life any easier than to work with pieces of the API by hand.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://central.isample.xyz/isamples_central/openapi.json is an OPENAPI 3.x spec\n",
    "\n",
    "OPENAPI_URL = 'https://central.isample.xyz/isamples_central/openapi.json'\n",
    "r = httpx.get(OPENAPI_URL)\n",
    "r.json()['paths'].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# /thing/select: Solr-based select interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# focus on /thing/select endpoint\n",
    "r = httpx.get(OPENAPI_URL)\n",
    "r.json()['paths']['/thing/select']['get']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# documentation about Solr query language\n",
    "\n",
    "[The Standard Query Parser | Apache Solr Reference Guide 8.11](https://solr.apache.org/guide/8_11/the-standard-query-parser.html#standard-query-parser-parameters):\n",
    "\n",
    "> Solr’s default Query Parser is also known as the “lucene” parser.   \n",
    "> [....]   \n",
    "> q: Defines a query using standard query syntax. This parameter is mandatory\n",
    "\n",
    "Note [Differences between Lucene’s Classic Query Parser and Solr’s Standard Query Parser](https://solr.apache.org/guide/8_11/the-standard-query-parser.html#differences-between-lucenes-classic-query-parser-and-solrs-standard-query-parser)\n",
    "\n",
    "there are \"existence searches\" [The Standard Query Parser | Apache Solr Reference Guide 8.11](https://solr.apache.org/guide/8_11/the-standard-query-parser.html#existence-searches):\n",
    "\n",
    "> An existence search for a field matches all documents where a value exists for that field. To query for a field existing, simply use a wildcard instead of a term in the search.\n",
    ">\n",
    "> field:*\n",
    ">\n",
    "> A field will be considered to \"exist\" if it has any value, even values which are often considered \"not existent\". (e.g., NaN, \"\", etc.)\n",
    "\n",
    "Good tutorial on the query syntax of Solr (apart from the official documentation): [Solr Query Syntax and Examples](https://yonik.com/solr/query-syntax/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## why the action is on fq and not q\n",
    "\n",
    "We set `q=*:*` and vary `fq`.  By doing so, you can cache results by varying `fq`. Also changing `fq` doesn't change the score.  (A better explanation should be put here because the distinction between `q` and `fq` is something that is not obvious to people new to Solr. ([Difference between q and fq in Solr - Stack Overflow](https://stackoverflow.com/questions/20988516/difference-between-q-and-fq-in-solr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Translate the UI from https://central.isample.xyz/isamples_central/ui into widgetized forms to formulate query\n",
    "\n",
    "* display number of hits\n",
    "* display facets\n",
    "\n",
    "map\n",
    "dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IsbClient2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cli = IsbClient2()\n",
    "\n",
    "# get OpenContext sourced records\n",
    "fq = cli._fq_from_kwargs(source=('OPENCONTEXT',), collection_date_end=str(datetime.now().year))\n",
    "\n",
    "params = cli.default_search_params(fq=fq, fl=FL_DEFAULT, rows=100, **FACET_RANGE_FIELDS_DEFAULT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cli.facets(params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the /thing/select endpoint directly\n",
    "response = cli.search(params=params, thingselect=True)\n",
    "# print number of hits\n",
    "print (response['response']['numFound'])\n",
    "\n",
    "df = DataFrame(response)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what's the number of records that are geocoded in OpenContext\n",
    "\n",
    "import multidict \n",
    "\n",
    "# get OpenContext sourced records\n",
    "# fq=-lat:[* TO *] AND -long:[* TO *]&rows=0\n",
    "# fq = cli._fq_from_kwargs(source=('OPENCONTEXT',), collection_date_end=str(datetime.now().year))\n",
    "geodict = multidict.MultiDict({\n",
    "  '-producedBy_samplingSite_location_latitude':'[* TO *]', \n",
    "  '-producedBy_samplingSite_location_longitude': '[* TO *]'\n",
    "})\n",
    "\n",
    "fq = cli._fq_from_kwargs(source=('OPENCONTEXT',), collection_date_end=str(datetime.now().year), \n",
    "        _multi=geodict )\n",
    "\n",
    "params = cli.default_search_params(fq=fq, fl=FL_DEFAULT, rows=100, **FACET_RANGE_FIELDS_DEFAULT)\n",
    "\n",
    "# use the /thing/select endpoint directly\n",
    "response = cli.search(params=params, thingselect=True)\n",
    "# print number of hits\n",
    "print (response['response']['numFound'])\n",
    "results = islice(response, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cli._fq_from_kwargs(source=('OPENCONTEXT',), collection_date_end=str(datetime.now().year), \n",
    "        producedBy_samplingSite_location_latitude='[* TO *]', producedBy_samplingSite_location_longitude='[* TO *]' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.getLogger().setLevel(logging.CRITICAL)\n",
    "\n",
    "# monkeypatch pysolr?\n",
    "monkey_patch_select(active=True)\n",
    "SWITCH_TO_POST = 100000\n",
    "\n",
    "cli = IsbClient2()\n",
    "# build fq: OpenContext source and search for bone\n",
    "fq = cli._fq_from_kwargs(source=('OPENCONTEXT',), searchText=\"bone\")\n",
    "params = cli.default_search_params(fq=fq, fl=FL_DEFAULT, rows=100, **FACET_RANGE_FIELDS_DEFAULT)\n",
    "\n",
    "# use pysolr to get the results\n",
    "response = cli.search(params=params)\n",
    "# print number of hits\n",
    "print (len(response))\n",
    "results = islice(response, 1000)\n",
    "\n",
    "df = DataFrame(results)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cli.record_count(params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# goal: figure out how to get facet counts and pivoting\n",
    "\n",
    "cli = IsbClient2()\n",
    "# build fq: OpenContext source and search for bone\n",
    "fq = cli._fq_from_kwargs(source=('OPENCONTEXT',), searchText=\"bone\")\n",
    "params = cli.default_search_params(fq=fq, fl=FL_DEFAULT, rows=100, **FACET_RANGE_FIELDS_DEFAULT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp0 = cli.search(params=params, thingselect=True)\n",
    "resp0.get(\"facet_counts\",{}).get(\"facet_fields\",{}).keys() #.get(field, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's look at the data coming back and see how to make sense of them.\n",
    "# expect the columns in the DataFrame to be a proper subset of FL_DEFAULT\n",
    "\n",
    "\n",
    "def set_diff(a, b):\n",
    "    return set(a) - set(b), set(b) - set(a)\n",
    "    \n",
    "\n",
    "\n",
    "assert set(df.columns) - set(FL_DEFAULT) == set()\n",
    "\n",
    "\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can I get type information from the API?\n",
    "# it doesn't seem like /thing/select will return type information\n",
    "\n",
    "# save a copy of df to df0\n",
    "df0 = df.copy()\n",
    "\n",
    "# df.infer_objects().dtypes\n",
    "df = df.convert_dtypes()\n",
    "\n",
    "# some of the columns are datetimes\n",
    "for k in ['sourceUpdatedTime', 'producedBy_resultTime', 'producedBy_resultTimeRange']:\n",
    "    df[k] = pd.to_datetime(df[k], errors='coerce').dt.tz_localize(None)\n",
    "\n",
    "# spit out to Excel to look at the data in spreadsheet form\n",
    "df.to_excel('bone.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sourceUpdatedTime'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Convert the datetime64 column to just date\n",
    "df['sourceUpdatedTime'] = df['sourceUpdatedTime'].dt.date\n",
    "\n",
    "# Plot a histogram\n",
    "plt.figure(figsize=(10,6))\n",
    "df['sourceUpdatedTime'].hist(rwidth=0.9, bins=30)\n",
    "plt.title('Distribution of sourceUpdatedTime')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipydatagrid as ipg\n",
    "ipg.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the df into ipydatagrid\n",
    "from ipydatagrid import DataGrid\n",
    "\n",
    "dg = DataGrid(df, editable=True)\n",
    "dg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what type of events are supported by ipydatagrid\n",
    "# selection events, what rows are shown? what columns?\n",
    "dg.selection_mode, dg.selected_cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_selection_from_dg(selection, total_rows, total_columns):\n",
    "    # Initialize counters\n",
    "    row_counts = {}\n",
    "    \n",
    "    # Process each selected cell\n",
    "    for cell in selection:\n",
    "        row_index = cell['r']\n",
    "        # Increment the row counter for each occurrence\n",
    "        if row_index in row_counts:\n",
    "            row_counts[row_index] += 1\n",
    "        else:\n",
    "            row_counts[row_index] = 1\n",
    "    \n",
    "    # Analyze the counts to determine full row selections\n",
    "    full_rows_selected = [row for row, count in row_counts.items() if count == total_columns]\n",
    "    \n",
    "    # Report findings\n",
    "    if full_rows_selected:\n",
    "        print(f\"Full rows selected: Rows {full_rows_selected}\")\n",
    "    else:\n",
    "        print(\"No full rows selected.\")\n",
    "\n",
    "# Assuming you have a DataFrame 'df' and a DataGrid 'dg' with selections as described\n",
    "total_rows, total_columns = df.shape  # As per your DataFrame's shape\n",
    "\n",
    "# Example selection (assuming this comes from dg.selected_cells)\n",
    "selected_cells =  dg.selected_cells\n",
    "# Analyze the selection\n",
    "analyze_selection_from_dg(selected_cells, total_rows, total_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use Jupyter widgets to allow for change in searchText and display the number of results in a output widget\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "logging.getLogger().setLevel(logging.CRITICAL)\n",
    "\n",
    "# monkeypatch pysolr?\n",
    "monkey_patch_select(active=True)\n",
    "SWITCH_TO_POST = 100000\n",
    "\n",
    "cli = IsbClient2()\n",
    "\n",
    "# build fq: OpenContext source and search for bone\n",
    "fq = cli._fq_from_kwargs(searchText=\"bone\")\n",
    "params = cli.default_search_params(fq=fq, fl=FL_DEFAULT, rows=10, **FACET_RANGE_FIELDS_DEFAULT)\n",
    "query = cli.search(params=params)\n",
    "num_hits = len(query)\n",
    "\n",
    "# Create a text input widget\n",
    "search_text = widgets.Text(\n",
    "    value='',\n",
    "    placeholder='Type something',\n",
    "    description='Search:',\n",
    ")\n",
    "\n",
    "# add a date range widget\n",
    "\n",
    "producedby_range_slider = widgets.IntRangeSlider(\n",
    "    value=[1800, 2024],\n",
    "    min=1800,\n",
    "    max=2024,\n",
    "    step=1,\n",
    "    description='ProducedBy ResultTime:',\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='d',\n",
    ")\n",
    "\n",
    "# Create an output widget\n",
    "output = widgets.Output()\n",
    "\n",
    "# Define a function to handle changes to the text input\n",
    "def on_text_change(change):\n",
    "    output.clear_output()  # Clear the previous results\n",
    "\n",
    "    # Get the new search text and range values\n",
    "    new_search_text = search_text.value\n",
    "    new_range = producedby_range_slider.value\n",
    "\n",
    "    fq = cli._fq_from_kwargs(searchText=new_search_text, collection_date_start=new_range[0], collection_date_end=new_range[1])\n",
    "    params = cli.default_search_params(fq=fq, fl=FL_DEFAULT, rows=10, **FACET_RANGE_FIELDS_DEFAULT)\n",
    "    query = cli.search(params=params)\n",
    "    num_hits = len(query)\n",
    "\n",
    "    with output:\n",
    "        print(f\"Number of hits: {num_hits}\")  # Display the new search text\n",
    "\n",
    "# Attach the event handler to the text input and range slider\n",
    "search_text.observe(on_text_change, names='value')\n",
    "producedby_range_slider.observe(on_text_change, names='value')\n",
    "\n",
    "# Display the widgets\n",
    "# align the widgets vertically\n",
    "display(widgets.VBox([producedby_range_slider, search_text, output]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write out the call to iSamples using httpx to compare get vs post\n",
    "\n",
    "import httpx\n",
    "ISB_SERVER = \"https://central.isample.xyz/isamples_central/\"\n",
    "\n",
    "r = httpx.request('GET', f'{ISB_SERVER}/thing/select', params=params)\n",
    "r.json()['response']['numFound']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a post request version\n",
    "\n",
    "from urllib.parse import urlencode\n",
    "\n",
    "headers = {\n",
    "    \"Content-type\": \"application/x-www-form-urlencoded; charset=utf-8\"\n",
    "}\n",
    "\n",
    "params_encoded = urlencode(params)\n",
    "r = httpx.post(f'{ISB_SERVER}/thing/select', data=params_encoded, headers=headers)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert set(query.raw_response.keys()) == set(['responseHeader', 'response', 'nextCursorMark', 'facet_counts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict_keys(['facet_queries', 'facet_fields', 'facet_ranges', 'facet_intervals', 'facet_heatmaps'])\n",
    "query.raw_response['facet_counts'].keys()\n",
    "\n",
    "query.raw_response['facet_counts']['facet_fields'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query.raw_response['facet_counts']['facet_fields']['source']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipytree import Tree, Node\n",
    "from ipyleaflet import Map, Marker\n",
    "from ipywidgets import HBox, link, Layout\n",
    "\n",
    "m = Map(center=[47.51, 4.04], zoom=4, layout=Layout(height='400px'))\n",
    "tree = Tree()\n",
    "tree.layout.width = '40%'\n",
    "box = HBox([tree, m])\n",
    "\n",
    "markers_node = Node('Markers')\n",
    "tree.add_node(markers_node)\n",
    "\n",
    "layers_node = Node('Layers', icon='map')\n",
    "tree.add_node(layers_node)\n",
    "\n",
    "cities = [\n",
    "    {'name': 'London', 'location': [51.5074, 0.1278]},\n",
    "    {'name': 'Paris', 'location': [48.8566, 2.3522]},\n",
    "    {'name': 'Barcelona', 'location': [41.31, 2.109]}\n",
    "]\n",
    "\n",
    "for city in cities:\n",
    "    marker = Marker(location=city.get('location'))\n",
    "    node = Node(city.get('name'), icon='map-marker')\n",
    "\n",
    "    link((marker, 'visible'), (node, 'selected'))\n",
    "\n",
    "    m.add_layer(marker)\n",
    "    markers_node.add_node(node)\n",
    "\n",
    "box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query.raw_response.keys() --> dict_keys(['responseHeader', 'response', 'nextCursorMark', 'facet_counts'])\n",
    "query.raw_response['facet_counts']['facet_ranges'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keys: dict_keys(['facet_queries', 'facet_fields', 'facet_ranges', 'facet_intervals', 'facet_heatmaps'])\n",
    "query.raw_response['facet_counts']['facet_ranges'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'responseHeader', 'index', 'schema', 'info'\n",
    "r = cli._request(\"thing/select/info\")\n",
    "r.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r['schema']['fields'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# timeout internal server error -- skip trying to query thing/types right now. https://github.com/isamplesorg/isamples_inabox/issues/351\n",
    "if False:\n",
    "    r = cli._request(\"thing/types\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# types and classnames for all the fields on the system\n",
    "Counter([(x['type'], r['schema']['types'][x['type']]['className']) for x in r['schema']['fields'].values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# e.g, I for Indexed, T for Tokenized, S for Stored, etc.\n",
    "r['info']['key']\n",
    "\n",
    "# ['fields', 'dynamicFields', 'uniqueKeyField', 'similarity', 'types']\n",
    "r['schema'].keys()\n",
    "\n",
    "# get the fields -- 78 of them\n",
    "print (\"number of fields\", len(r['schema']['fields'].keys()))\n",
    "\n",
    "field_names = cli.field_names()\n",
    "print(\"number of field names (another way to access)\", len(field_names))\n",
    "\n",
    "print (\"types for the major fields\")\n",
    "[(k,v['type'], r['schema']['types'][v['type']]['className'] ) for (k,v) in r['schema']['fields'].items() if k in MAJOR_FIELDS.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlparse, parse_qs\n",
    "\n",
    "url = 'https://central.isample.xyz/isamples_central/thing/select?q=*:*&fl=searchText%20authorizedBy%20producedBy_resultTimeRange%20hasContextCategory%20curation_accessContraints%20curation_description_text%20curation_label%20curation_location%20curation_responsibility%20description_text%20id%20informalClassification%20keywords%20label%20hasMaterialCategory%20producedBy_description_text%20producedBy_hasFeatureOfInterest%20producedBy_label%20producedBy_responsibility%20producedBy_resultTime%20producedBy_samplingSite_description_text%20producedBy_samplingSite_label%20producedBy_samplingSite_location_elevationInMeters%20producedBy_samplingSite_location_latitude%20producedBy_samplingSite_location_longitude%20producedBy_samplingSite_placeName%20registrant%20samplingPurpose%20source%20sourceUpdatedTime%20producedBy_samplingSite_location_rpt%20hasSpecimenCategory&fq=producedBy_resultTimeRange%3A%5B1800%20TO%202023%5D&fq=source%3A(%22OPENCONTEXT%22%20OR%20%22SESAR%22)&fq=-relation_target%3A*&facet.field=authorizedBy&facet.field=hasContextCategory&facet.field=hasMaterialCategory&facet.field=registrant&facet.field=source&facet.field=hasSpecimenCategory&facet.range=producedBy_resultTimeRange&facet.range.gap=%2B1YEARS&facet.range.start=1800-01-01T00:00:00Z&facet.range.end=2023-01-01T00:00:00Z&f.registrant.facet.sort=count&f.source.facet.sort=index&rows=20&facet.limit=-1&facet.sort=index&&start=0&facet=on&wt=json'\n",
    "\n",
    "parsed_url = urlparse(url)\n",
    "query_params = parse_qs(parsed_url.query)\n",
    "\n",
    "# The result is a dictionary where each key is associated with a list of values.\n",
    "# You can iterate over this dictionary to process your parameters as needed.\n",
    "for key, values in query_params.items():\n",
    "    print(f\"{key}: {values}\")\n",
    "\n",
    "# If you need each key to have a single value (taking the first value if multiple are present),\n",
    "# you can do the following:\n",
    "single_value_params = {key: values[0] for key, values in query_params.items()}\n",
    "print(single_value_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simplest query -- default\n",
    "\n",
    "cli._request(\"thing/select\", params={'q': '*:*', 'start':0, 'rows': 10, \n",
    "        'fq': ['producedBy_resultTimeRange:[1800 TO 2023]', 'source:(OPENCONTEXT or SESAR)', '-relation_target:*'],\n",
    "        'facet.field': ['authorizedBy', 'hasContextCategory', 'hasMaterialCategory', 'registrant', 'source', 'hasSpecimenCategory'],\n",
    "        'facet': 'on',\n",
    "        })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I *think* I had ChatGPT parse the parameters and give me the following interpretation:\n",
    "\n",
    "Let's break down these parameters, which are used for querying a Solr search engine. Solr is an open-source search platform that provides a wide range of capabilities for text search and faceted search, among other features.\n",
    "\n",
    "q: This parameter specifies the query. Here, *:* is a wildcard query, meaning it matches all documents in the Solr index.\n",
    "\n",
    "\n",
    "[fl](https://solr.apache.org/guide/8_11/common-query-parameters.html#fl-field-list-parameter): This stands for \"field list\". It specifies the fields to return in the result. In your query, a long list of fields like searchText, authorizedBy, producedBy_resultTimeRange, etc., are included. Only these fields will be returned for each document in the search results.\n",
    "\n",
    "fq: This is the \"filter query\". It filters the results returned by the main query (q) without influencing the score. Here, there are three filters applied:\n",
    "\n",
    "> producedBy_resultTimeRange:[1800 TO 2023] filters documents to those produced between the years 1800 and 2023.\n",
    "source:(OPENCONTEXT) filters documents where the source field matches \"OPENCONTEXT\".\n",
    "-relation_target:* excludes documents where the relation_target field exists.\n",
    "facet.field: Faceting is used to aggregate data based on a field. This parameter specifies the fields for which you want to see facet counts. Facets on fields like authorizedBy, hasContextCategory, etc., are requested.\n",
    "\n",
    "\n",
    "facet.range, facet.range.gap, facet.range.start, and facet.range.end: These parameters are used for range faceting. You are faceting on the producedBy_resultTimeRange field, starting from \"1800-01-01T00:00:00Z\" to \"2023-01-01T00:00:00Z\", with a gap of \"+1YEARS\". This means it will provide counts for each year in this range.\n",
    "\n",
    "f.registrant.facet.sort and f.source.facet.sort: These are sorting instructions for the facets. The registrant facet is sorted by count, and the source facet is sorted by index.\n",
    "\n",
    "rows: This specifies the number of documents to return. In your query, it's set to 20.\n",
    "\n",
    "facet.limit: This limits the number of facet values returned for each facet field. -1 means no limit.\n",
    "\n",
    "facet.sort: It dictates how to sort the facet fields. Here, it's sorted by index.\n",
    "\n",
    "start: This is the offset in the complete result set for pagination. It tells Solr where to start in the list of results (useful for paging through results).\n",
    "\n",
    "facet: When set to 'on', it enables faceting.\n",
    "\n",
    "wt: This stands for \"writer type\" and specifies the output format. Here, 'json' indicates that the response should be in JSON format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import httpx\n",
    "\n",
    "\n",
    "url = \"https://central.isample.xyz/isamples_central/thing/select\"\n",
    "params = {\n",
    "    'q': '*:*',\n",
    "    'fl': 'searchText authorizedBy producedBy_resultTimeRange hasContextCategory curation_accessContraints curation_description_text curation_label curation_location curation_responsibility description_text id informalClassification keywords label hasMaterialCategory producedBy_description_text producedBy_hasFeatureOfInterest producedBy_label producedBy_responsibility producedBy_resultTime producedBy_samplingSite_description_text producedBy_samplingSite_label producedBy_samplingSite_location_elevationInMeters producedBy_samplingSite_location_latitude producedBy_samplingSite_location_longitude producedBy_samplingSite_placeName registrant samplingPurpose source sourceUpdatedTime producedBy_samplingSite_location_rpt hasSpecimenCategory',\n",
    "    'fq': ['producedBy_resultTimeRange:[1800 TO 2023]', 'source:(OPENCONTEXT)', '-relation_target:*'],\n",
    "    'facet.field': ['authorizedBy', 'hasContextCategory', 'hasMaterialCategory', 'registrant', 'source', 'hasSpecimenCategory'],\n",
    "    'facet.range': 'producedBy_resultTimeRange',\n",
    "    'facet.range.gap': '+1YEARS',\n",
    "    'facet.range.start': '1800-01-01T00:00:00Z',\n",
    "    'facet.range.end': '2023-01-01T00:00:00Z',\n",
    "    'f.registrant.facet.sort': 'count',\n",
    "    'f.source.facet.sort': 'index',\n",
    "    'rows': '20',\n",
    "    'facet.limit': '-1',\n",
    "    'facet.sort': 'index',\n",
    "    'start': '20',\n",
    "    'facet': 'on',\n",
    "    'wt': 'json'\n",
    "}\n",
    "headers = {\n",
    "    'Accept': 'application/json',\n",
    "    'User-Agent': 'raymondyee.net'\n",
    "}\n",
    "\n",
    "# keys in response: 'responseHeader', 'response', 'facet_counts'\n",
    "response = httpx.get(url, params=params, headers=headers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get back parameters that went into the query and some basic metadata\n",
    "response.json()['responseHeader']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'numFound', 'start', 'numFoundExact', 'docs'\n",
    "response.json()['response'].keys()\n",
    "\n",
    "(response.json()['response']['numFound'], response.json()['response']['numFoundExact'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response.json()['response']['docs'][0].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plotting the collection dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import httpx\n",
    "\n",
    "cli = IsbClient2()\n",
    "fq = cli._fq_from_kwargs(source=('OPENCONTEXT',))\n",
    "params = cli.default_search_params(fq=fq, fl=FL_DEFAULT, rows=100, **FACET_RANGE_FIELDS_DEFAULT)\n",
    "\n",
    "\n",
    "url = 'https://central.isample.xyz/isamples_central/thing/select/info'\n",
    "url = 'https://central.isample.xyz/isamples_central/thing/select?q=*:*&facet=true&facet.range=producedBy_resultTimeRange&facet.range.start=NOW/YEAR-200YEARS&facet.range.end=NOW/YEAR&facet.range.gap=YEAR'\n",
    "\n",
    "\n",
    "headers = {\n",
    "    'accept': 'application/json'\n",
    "}\n",
    "\n",
    "response = httpx.get('https://central.isample.xyz/isamples_central/thing/select', headers=headers, params=params)\n",
    "\n",
    "print(response.json())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response.json()['facet_counts']['facet_ranges']['producedBy_resultTimeRange']['counts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "k = response.json()['facet_counts']['facet_ranges']['producedBy_resultTimeRange']['counts']\n",
    "dict(zip(k[::2], k[1::2]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming data is your response.json()['facet_counts']['facet_ranges']['producedBy_resultTimeRange']['counts']\n",
    "k = response.json()['facet_counts']['facet_ranges']['producedBy_resultTimeRange']['counts']\n",
    "data = dict(zip(k[::2], k[1::2]))\n",
    "\n",
    "\n",
    "# Convert the dictionary to a DataFrame\n",
    "df = pd.DataFrame(list(data.items()), columns=['Date', 'Count'])\n",
    "\n",
    "# Convert the 'Date' column to datetime\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# Extract the year from the date\n",
    "df['Year'] = df['Date'].dt.year\n",
    "\n",
    "# Count the occurrences of each year\n",
    "year_counts = df['Year'].value_counts().sort_index()\n",
    "\n",
    "# Plot the counts vs year\n",
    "year_counts.plot(kind='line')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Count vs Year')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = response.json()['facet_counts']['facet_ranges']['producedBy_resultTimeRange']['counts']\n",
    "data = dict(zip(k[::2], k[1::2]))\n",
    "\n",
    "df = pd.DataFrame(list(data.items()), columns=['Date', 'Count'])\n",
    "df.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# deal with log scale\n",
    "df = df.loc[df['Count'] != 0]\n",
    "\n",
    "# df['Count'] = df['Count'].replace(0, np.nan)\n",
    "# df['Count'] = df['Count'].fillna(0.1)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.scatter(df['Date'], df['Count'], color='green', alpha=0.5, s=10)\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Count over Date')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "curl -X 'GET' \\\n",
    "  'https://central.isample.xyz/isamples_central/thing/select?facet=true&facet.mincount=0&facet.field=source' \\\n",
    "  -H 'accept: application/json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(field_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get OpenContext sourced records\n",
    "# fq = cli._fq_from_kwargs(source=('OPENCONTEXT', 'SESAR'), collection_date_end=str(datetime.now().year))\n",
    "fq = cli._fq_from_kwargs(collection_date_end=str(datetime.now().year))\n",
    "\n",
    "params = cli.default_search_params(fq=fq, fl=FL_DEFAULT, rows=100, **FACET_RANGE_FIELDS_DEFAULT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get counts of values grouping by three dimensions: source, hasMaterialCategory, and hasContextCategory\n",
    "dimensions = [\"source\", \"hasMaterialCategory\", \"hasContextCategory\"]\n",
    "xd = cli.pivot(params, dimensions)\n",
    "print(xd.loc[\"geome\", \"organic material\", \"bacteria\"].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum by axis 2 (hasContextCategory) and print\n",
    "df = xd.sum(axis=2).to_pandas()\n",
    "# display transposed\n",
    "display(df.T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(xd.loc[\"sesar\", \"rock\"].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Field names in solr\n",
    "for name in cli.field_names():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bulk Download\n",
    "\n",
    "\n",
    "[isamples\\_inabox/docs/export\\_service.md at develop · isamplesorg/isamples\\_inabox](https://github.com/isamplesorg/isamples_inabox/blob/develop/docs/export_service.md)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "ISAMPLES_TOKEN = os.environ.get(\"ISAMPLES_TOKEN\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%pybash\n",
    "\n",
    "echo \"{ISAMPLES_TOKEN}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%pybash\n",
    "\n",
    "curl  -H \"Authorization: Bearer {ISAMPLES_TOKEN}\" \"https://central.isample.xyz/isamples_central/export/create?q=source:SMITHSONIAN&export_format=jsonl\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%pybash\n",
    "\n",
    "curl  \"https://central.isample.xyz/isamples_central/export/status?uuid=3a352569-cd03-488f-880b-e1a1252f2b18\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%pybash\n",
    "\n",
    "curl -o /tmp/3a352569-cd03-488f-880b-e1a1252f2b18.jsonl \"https://central.isample.xyz/isamples_central/export/download?uuid=3a352569-cd03-488f-880b-e1a1252f2b18\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%pybash\n",
    "\n",
    "ls -lt /tmp/3a352569-cd03-488f-880b-e1a1252f2b18.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"/tmp/3a352569-cd03-488f-880b-e1a1252f2b18.jsonl\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "df_bulk = pd.read_json(\"/tmp/3a352569-cd03-488f-880b-e1a1252f2b18.jsonl\", lines=True)\n",
    "df_bulk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from isbclient import ISamplesBulkHandler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "query = \"source:SMITHSONIAN\"\n",
    "\n",
    "ish = ISamplesBulkHandler(token=ISAMPLES_TOKEN)\n",
    "uuid = ish.create_download(query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ish.get_status(uuid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ish.download_file(uuid, f\"/tmp/{uuid}.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bulk = ish.load_dataset_to_dataframe(f\"/tmp/{uuid}.jsonl\")\n",
    "df_bulk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geoparquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "\n",
    "# Connect to an in-memory DuckDB instance\n",
    "con = duckdb.connect()\n",
    "\n",
    "# Load the GeoParquet file\n",
    "geo_parquet_file = '/Users/raymondyee/Data/iSample/2024_06_07_07_40_00/isamples_export_2024_06_07_07_40_00_geo.parquet'\n",
    "\n",
    "# Query the GeoParquet file\n",
    "query = f\"SELECT * FROM read_parquet('{geo_parquet_file}')\"\n",
    "df = con.execute(query).df()\n",
    "\n",
    "# Display the first few rows of the dataframe\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Convert the DuckDB dataframe to a GeoDataFrame\n",
    "gdf = gpd.GeoDataFrame(df, geometry='geometry')\n",
    "\n",
    "# Plot the geospatial data\n",
    "gdf.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datashader as ds\n",
    "import datashader.transfer_functions as tf\n",
    "from datashader.utils import lnglat_to_meters\n",
    "\n",
    "# Convert longitude and latitude to meters for better visualization\n",
    "gdf['x'], gdf['y'] = lnglat_to_meters(gdf.geometry.x, gdf.geometry.y)\n",
    "\n",
    "# Create a canvas for the plot\n",
    "canvas = ds.Canvas(plot_width=800, plot_height=600)\n",
    "\n",
    "# Aggregate the data\n",
    "agg = canvas.points(gdf, 'x', 'y')\n",
    "\n",
    "# Create an image from the aggregated data\n",
    "img = tf.shade(agg, cmap='viridis')\n",
    "\n",
    "# Display the image\n",
    "img.to_pil().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
